{"cells":[{"metadata":{},"cell_type":"markdown","source":"Contents:\n\nFirst I do some basic analysis of the tweets\nthen I try a bunch of methods.\n\n*  Ridge classifier that gets us upto 79.5%  (from the getting-started tutorial)\n*  Logistic Regression with differing parameters\n*  Decision Tree\n*  BERT"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict, Counter\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud \nfrom nltk.tokenize import word_tokenize ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df[\"target\"] == 0][\"text\"].values[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df[\"target\"] == 1][\"text\"].values[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets analyze the tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords_vc = pd.DataFrame({\"Count\": train_df[\"keyword\"].value_counts()})\nsns.barplot(y=keywords_vc[0:30].index, x=keywords_vc[0:30][\"Count\"], orient='h')\nplt.title(\"Top 30 Keywords\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"THIS method of visualiztion was inspired by Zineb khanjari"},{"metadata":{"trusted":true},"cell_type":"code","source":"disaster_keywords = train_df.loc[train_df[\"target\"] == 1][\"keyword\"].value_counts()\nnondisaster_keywords = train_df.loc[train_df[\"target\"] == 0][\"keyword\"].value_counts()\n\nfig, ax = plt.subplots(1,2, figsize=(20,8))\nsns.barplot(y=disaster_keywords[0:30].index, x=disaster_keywords[0:30], orient='h', ax=ax[0], palette=\"Reds_d\")\nsns.barplot(y=nondisaster_keywords[0:30].index, x=nondisaster_keywords[0:30], orient='h', ax=ax[1], palette=\"Blues_d\")\nax[0].set_title(\"Top 30 Keywords - Disaster Tweets\")\nax[0].set_xlabel(\"Keyword Frequency\")\nax[1].set_title(\"Top 30 Keywords - Non-Disaster Tweets\")\nax[1].set_xlabel(\"Keyword Frequency\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Its worth exploring to see if these top frequency words are really indicative of the label:\nlets explore this aspect for the top few words"},{"metadata":{"trusted":true},"cell_type":"code","source":"def keyword_disaster_probabilities(x):\n    tweets_w_keyword = np.sum(train_df[\"keyword\"].fillna(\"\").str.contains(x))\n    tweets_w_keyword_disaster = np.sum(train_df[\"keyword\"].fillna(\"\").str.contains(x) & train_df[\"target\"] == 1)\n    return tweets_w_keyword_disaster / tweets_w_keyword\n\nkeywords_vc[\"Disaster_Probability\"] = keywords_vc.index.map(keyword_disaster_probabilities)\nkeywords_vc.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets observe what words are most indicative"},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords_vc.sort_values(by=\"Disaster_Probability\", ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us look ta the tweet length distribution.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"tweet_length\"] = train_df[\"text\"].apply(len)\nsns.distplot(train_df[\"tweet_length\"])\nplt.title(\"Histogram of Tweet Length\")\nplt.xlabel(\"Number of Characters\")\nplt.ylabel(\"Density\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Might be more useful to see if there is a difference based on the label."},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(train_df, col=\"target\", height=5)\ng = g.map(sns.distplot, \"tweet_length\")\nplt.suptitle(\"Distribution  of Tweet Length\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building vectors\n\nThe theory behind the model we'll build in this notebook is pretty simple: the words contained in each tweet are a good indicator of whether they're about a real disaster or not (this is not entirely correct, but it's a great place to start).\n\nWe'll use scikit-learn's `CountVectorizer` to count the words in each tweet and turn them into data our machine learning model can process.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = feature_extraction.text.CountVectorizer()\n\n## let's get counts for the first 5 tweets in the data\nexample_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"text\"][0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\nprint(example_train_vectors[0].todense().shape)\nprint(example_train_vectors[0].todense())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above tells us that:\n1. There are 54 unique words (or \"tokens\") in the first five tweets.\n2. The first tweet contains only some of those unique tokens - all of the non-zero counts above are the tokens that DO exist in the first tweet.\n\nNow let's create vectors for all of our tweets."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n\n## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n# that the tokens in the train vectors are the only ones mapped to the test vectors - \n# i.e. that the train and test vectors use the same set of tokens.\ntest_vectors = count_vectorizer.transform(test_df[\"text\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ridge Classifier\n\nAs we mentioned above, we think the words contained in each tweet are a good indicator of whether they're about a real disaster or not. The presence of particular word (or set of words) in a tweet might link directly to whether or not that tweet is real.\n\nWhat we're assuming here is a _linear_ connection. So let's build a linear model and see!"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Our vectors are really big, so we want to push our model's weights\n## toward 0 without completely discounting different words - ridge regression \n## is a good way to do this.\nclf = linear_model.RidgeClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's test our model and see how well it does on the training data. For this we'll use `cross-validation` - where we train on a portion of the known data, then validate it with the rest. If we do this several times (with different portions) we can get a good idea for how a particular model or method performs.\n\nThe metric for this competition is F1, so let's use that here."},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above scores aren't terrible! It looks like our assumption will score roughly 0.65 on the leaderboard. There are lots of ways to potentially improve on this (TFIDF, LSA, LSTM / RNNs, the list is long!) - give any of them a shot!\n\nIn the meantime, let's do predictions on our training set and build a submission for the competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(train_vectors, train_df[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission[\"target\"] = clf.predict(test_vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)Lets try different hyperparametes.\n\nAfter some tuning, max_df = 180 seemed to work well"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = feature_extraction.text.CountVectorizer(max_df = 180, stop_words = 'english')\ntrain_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\ntrain_vectors[0].todense().shape\ntest_vectors = count_vectorizer.transform(test_df['text'])\ntest_vectors[0].todense().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = linear_model.RidgeClassifier(alpha = 20)\nclf.fit(train_vectors, train_df['target'])\nscores = model_selection.cross_val_score(clf, train_vectors, train_df['target'], cv=3, scoring = 'f1')\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This one gets about 79.5%\n(I just run above cell to save the csv)"},{"metadata":{},"cell_type":"markdown","source":"Now we try decision tree from SKLearn"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([  ('clf', DecisionTreeClassifier( splitter='random', class_weight='balanced'))\n])\nparameters = {\n    'clf__max_depth':(150,160,165),\n    'clf__min_samples_split':(18,20,23),\n    'clf__min_samples_leaf':(5,6,7)\n}\n\ndf_tfidf = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=-1, scoring='f1')\ndf_tfidf.fit(X_train_tfidf, y_train)\n\nprint(df_tfidf.best_estimator_.get_params())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, inspired by some high scoring submissions, I decided to use TF-IDF vectorizer. Starting with something simple, lets consider logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([train_df, test_df])\n\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = data[0:train_df.shape[0]]\ndata_test = data[train_df.shape[0]:-1]\n\nX_train, X_test, y_train, y_test = train_test_split(data_train['text'], data_train['target'],\n                                            test_size = 0.2, random_state = 75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# id_train=train_df.id\n# text_train=list(train_df.text)\n\n# y_train=train_df.target.values\n# id_test=train_df.id\n# text_test=list(test_df.text)\n# text=text_train+text_test\n# print(len(text))\n# lentraindata=\ntfv = TfidfVectorizer(  max_features=None,tokenizer=None,ngram_range=(1,1)\n    ,analyzer='word', use_idf=1,smooth_idf=1,sublinear_tf=1)\n\nX = tfv.fit_transform(text)\n\nX_train = X[:len(text_train)]\nX_test = X[len(text_train):]\n\nlr = LogisticRegression(C=1,max_iter=10000)\n\nprint('Cross val score: {}'.format(np.mean(cross_val_score(lr,X_train,y_train, cv=10))))\n\nlr.fit(X_train,y_train)\ny_predict = lr.predict(X_test)\n\n# submission_df = pd.DataFrame(y_predict)\n# submission_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tfidf = tfv.fit_transform(X_train)\ntest_tfidf = tfv.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before generating submission we can train it on the whole dataset (both training and testing split)!"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_df.target.values\nX = tfv.fit_transform(text)\n# lr.fit(X,y_train)\n# y_predict = lr.predict(X_test)\n\n# submission_df = pd.DataFrame(y_predict)\n# submission_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(class_weight = 'balanced', solver = 'lbfgs', n_jobs = -1)\nlr.fit(train_tfidf, y_train)\n# y_predicted_lr = lr.predict(test_tfidf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This gets us 74.23% accuracy with something as simple as logistic regression!"},{"metadata":{},"cell_type":"markdown","source":"Inspired by the top scoring submission, I decided to try out a pre-trained model like BERT,\nMost straightforwardly from huggingface "},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer\nimport numpy as np\nimport tensorflow as tf \nfrom transformers import TFBertModel\nimport transformers\n\nbert_model = TFBertModel.from_pretrained('bert-large-uncased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model(bert_model)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit([train_input_ids,train_attention_masks],train.target,validation_split=0.2, epochs=2,batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = model.predict([test_input_ids,test_attention_masks])\nout = np.round(out).astype(int)\nresult = pd.DataFrame(result)\nsubmission = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\noutput = pd.DataFrame({'id':submission.id,'target':result[0]})\noutput.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We finally managed to push our accuracy to 84% !"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}